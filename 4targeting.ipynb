{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Targeting Simulations\n",
    "Replication code for:\n",
    "- Figure 1 and Table 1\n",
    "- Figure 2\n",
    "- Figure S2\n",
    "- Figure S12\n",
    "- Figure S13\n",
    "- Table S1\n",
    "- Table S2\n",
    "- Table S3\n",
    "- Table S5\n",
    "- Table S13\n",
    "- Table S14\n",
    "- Table S15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from scipy.stats import percentileofscore\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_bootstraps = 10 # Change to 1000 for real implementation, keep at 10 for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load survey data\n",
    "survey = pd.read_csv('data/survey2018.csv')\n",
    "\n",
    "# Merge survey data with poverty maps\n",
    "prefectures = gpd.read_file('data/shapefiles/prefectures.geojson')\\\n",
    "    .rename({'poverty':'prefecture_poverty'}, axis=1)\\\n",
    "    [['prefecture', 'prefecture_poverty']]\n",
    "survey = survey.merge(prefectures, on='prefecture', how='left')\n",
    "cantons = gpd.read_file('data/shapefiles/cantons.geojson')\\\n",
    "    .rename({'poverty':'canton_poverty'}, axis=1)\\\n",
    "    [['canton', 'canton_poverty']]\n",
    "survey = survey.merge(cantons, on='canton', how='left')\n",
    "\n",
    "# Merge survey data with phone-based poverty predictions\n",
    "cdr = pd.read_csv('outputs/ml/consumption/LGBM/oos_predictions.csv')\\\n",
    "    [['phone_number', 'predicted']]\\\n",
    "    .rename({'predicted':'phone_poverty'}, axis=1)\n",
    "survey = survey.merge(cdr, on='phone_number', how='left')\n",
    "\n",
    "# Merge survey with \"old\" phone-based poverty predictions with \"old\" CDR\n",
    "cdr = pd.read_csv('outputs/ml/consumption/LGBM/oos_predictions.csv')\\\n",
    "    [['phone_number', 'predicted']]\\\n",
    "    .rename({'predicted':'phone_poverty_old_model_old_data'}, axis=1)\n",
    "survey = survey.merge(cdr, on='phone_number', how='left')\n",
    "\n",
    "# Merge survey with \"old\" phone-based poverty predictions with \"new\" CDR\n",
    "cdr = pd.read_csv('outputs/ml/consumption/temporality/old_model_new_data.csv')\\\n",
    "    [['phone_number', 'prediction']]\\\n",
    "    .rename({'prediction':'phone_poverty_old_model_new_data'}, axis=1)\n",
    "survey = survey.merge(cdr, on='phone_number', how='left')\n",
    "\n",
    "# Merge survey data with phone-based single feature\n",
    "single_feature = pd.read_csv('data/single_feature2018.csv')\n",
    "survey = survey.merge(single_feature, on='phone_number', how='left')\n",
    "\n",
    "# Merge survey data with phone-based location\n",
    "homes = pd.read_csv('data/inferred_home_locations2018.csv').drop('region', axis=1)\n",
    "homes = homes.merge(prefectures, on='prefecture', how='left')\n",
    "homes = homes.merge(cantons, on='canton', how='left')\n",
    "homes = homes.rename({'prefecture':'phone_prefecture', 'canton':'phone_canton', \n",
    "                      'prefecture_poverty':'phone_prefecture_poverty', \n",
    "                      'canton_poverty':'phone_canton_poverty'}, axis=1)\n",
    "survey = survey.merge(homes, on='phone_number', how='left')\n",
    "\n",
    "# Add random outcome\n",
    "np.random.seed(0)\n",
    "survey['random'] = np.random.rand(len(survey))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S2 panel b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5, style='white')\n",
    "\n",
    "df = survey[['phone_poverty', 'consumption', 'canton', 'weight']].dropna()\n",
    "df_repeat = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)\n",
    "percent_targeted = 29\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "cons_threshold = np.percentile(df_repeat['consumption'], percent_targeted)\n",
    "phone_threshold = np.percentile(df_repeat['phone_poverty'], percent_targeted)\n",
    "\n",
    "ci = df[(df['consumption'] <= cons_threshold) & (df['phone_poverty'] <= phone_threshold)]\n",
    "ce = df[(df['consumption'] > cons_threshold) & (df['phone_poverty'] > phone_threshold)]\n",
    "ii = df[(df['consumption'] > cons_threshold) & (df['phone_poverty'] <= phone_threshold)]\n",
    "ie = df[(df['consumption'] <= cons_threshold) & (df['phone_poverty'] > phone_threshold)]\n",
    "\n",
    "ax[0].scatter(ci['consumption'], ci['phone_poverty'], color='mediumseagreen', s=100)\n",
    "ax[0].scatter(ie['consumption'], ie['phone_poverty'], color='mediumseagreen', alpha=0.3, s=100)\n",
    "ax[0].scatter(ii['consumption'], ii['phone_poverty'], color='indianred', s=100)\n",
    "ax[0].scatter(ce['consumption'], ce['phone_poverty'], color='indianred', alpha=0.3, s=100)\n",
    "ax[0].axhline(phone_threshold, color='black', dashes=[7, 7])\n",
    "ax[0].axvline(cons_threshold, color='black', dashes=[2, 2])\n",
    "ax[0].set_xlabel('Ground Truth Consumption')\n",
    "ax[0].set_ylabel('Predicted Consumption')\n",
    "simpleaxis(ax[0])\n",
    "\n",
    "eligible_cantons = [1, 2, 3, 4, 5, 6, 7, 8, 9, 19]\n",
    "sns.kdeplot(df[df['canton'].isin(eligible_cantons)]['phone_poverty'], ax=ax[1], shade=True, \n",
    "            label='Eligible Cantons')\n",
    "sns.kdeplot(df['phone_poverty'], ax=ax[1], shade=True, label='All Togo')\n",
    "ax[1].set_xlabel('Predicted Consumption')\n",
    "ax[1].set_ylabel('Density')\n",
    "ax[1].axvline(phone_threshold, dashes=[7, 7], color='black')\n",
    "simpleaxis(ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1, Figure 1, Table S1, Table S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_methods = ['prefecture_poverty', 'canton_poverty', 'single_feature', 'phone_poverty', 'assetindex',\n",
    "                    'ppi', 'pmt', 'random', 'formal_occupation', 'occupation_poverty']\n",
    "outcome = 'consumption'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=targeting_methods + [outcome]).copy()\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "\n",
    "bootstraps = get_bootstraps(df, n_bootstraps)\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the poorest 29%\n",
    "fname = 'outputs/targeting/table1'\n",
    "percent_targeted = 29\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, percent_targeted, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting those below the poverty line\n",
    "fname = 'outputs/targeting/tables2'\n",
    "percent_targeted = 29\n",
    "poverty_line = 1800\n",
    "poverty_threshold = percentileofscore(df[outcome], poverty_line)\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, poverty_threshold, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting those below the poverty line\n",
    "fname = 'outputs/targeting/tables3'\n",
    "percent_targeted = 29\n",
    "poverty_line = 1000\n",
    "poverty_threshold = percentileofscore(df[outcome], poverty_line)\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, poverty_threshold, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table S13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PMT as ground truth\n",
    "targeting_methods = ['prefecture_poverty', 'canton_poverty', 'single_feature', 'phone_poverty', 'assetindex',\n",
    "                    'ppi', 'random', 'formal_occupation', 'occupation_poverty']\n",
    "outcome = 'pmt'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=targeting_methods + [outcome]).copy()\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "\n",
    "bootstraps = get_bootstraps(df, n_bootstraps)\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the poorest 29%\n",
    "fname = 'outputs/targeting/table13'\n",
    "percent_targeted = 29\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, percent_targeted, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In rural areas only, with consumption as ground truth\n",
    "targeting_methods = ['prefecture_poverty', 'canton_poverty', 'single_feature', 'phone_poverty', 'assetindex',\n",
    "                    'ppi', 'pmt', 'random', 'formal_occupation', 'occupation_poverty']\n",
    "outcome = 'consumption'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = df[df['milieu'] == 'rural']\n",
    "df = survey.dropna(subset=targeting_methods + [outcome]).copy()\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "\n",
    "bootstraps = get_bootstraps(df, n_bootstraps)\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the poorest 29%\n",
    "fname = 'outputs/targeting/tables3'\n",
    "percent_targeted = 29\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, percent_targeted, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table S14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In rural areas only, with rural-specific PMT as ground truth\n",
    "targeting_methods = ['prefecture_poverty', 'canton_poverty', 'single_feature', 'phone_poverty', 'assetindex',\n",
    "                    'ppi', 'random', 'formal_occupation', 'occupation_poverty']\n",
    "outcome = 'rural_pmt'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = df[df['milieu'] == 'rural']\n",
    "df = survey.dropna(subset=targeting_methods + [outcome]).copy()\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "\n",
    "bootstraps = get_bootstraps(df, n_bootstraps)\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the poorest 29%\n",
    "fname = 'outputs/targeting/tables14'\n",
    "percent_targeted = 29\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, percent_targeted, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table S15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic targeting with phone-inferred location\n",
    "targeting_methods = ['prefecture_poverty', 'canton_poverty', 'phone_prefecture_poverty', 'phone_canton_poverty',\n",
    "                    'phone_poverty']\n",
    "outcome = 'consumption'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=targeting_methods + [outcome]).copy()\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "\n",
    "bootstraps = get_bootstraps(df, n_bootstraps)\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the poorest 29%\n",
    "fname = 'outputs/targeting/tables15'\n",
    "percent_targeted = 29\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, percent_targeted, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_methods = ['phone_poverty', 'phone_poverty_old_model_new_data', 'phone_poverty_old_model_old_data',\n",
    "                    'prefecture_poverty', 'canton_poverty']\n",
    "outcome = 'consumption'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=targeting_methods + [outcome]).copy()\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "\n",
    "bootstraps = get_bootstraps(df, n_bootstraps)\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the poorest 29%\n",
    "fname = 'outputs/targeting/tables5panela'\n",
    "percent_targeted = 29\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, percent_targeted, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting those below the poverty line\n",
    "fname = 'outputs/targeting/tables5panelb'\n",
    "percent_targeted = 29\n",
    "poverty_line = 1800\n",
    "poverty_threshold = percentileofscore(df[outcome], poverty_line)\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, poverty_threshold, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting those below the poverty line\n",
    "fname = 'outputs/targeting/tables5panelc'\n",
    "percent_targeted = 29\n",
    "poverty_line = 1000\n",
    "poverty_threshold = percentileofscore(df[outcome], poverty_line)\n",
    "t = table((df, outcome, targeting_methods, targeting_methods, poverty_threshold, percent_targeted, True))\n",
    "t_std = std_table(((bootstraps, outcome, targeting_methods, targeting_methods, percent_targeted, \n",
    "                    percent_targeted, True)))\n",
    "t.to_csv(fname + '.csv', index=False)\n",
    "t_std.to_csv(fname +'_bootstrap.csv')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = ['prefecture_poverty', 'canton_poverty', 'phone_poverty', 'assetindex', 'pmt']\n",
    "proxynames = ['Prefecture', 'Canton', 'Phone+ML', 'Asset Index', 'PMT']\n",
    "colors = ['indianred', 'darkorange', 'forestgreen', 'dodgerblue', 'darkblue']\n",
    "dashes = [False, False, False, True, True]\n",
    "\n",
    "outcome = 'consumption'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=proxies + [outcome]).copy()\n",
    "\n",
    "# Generate repeated dataframe to account for weighting\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2, style='white')\n",
    "fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "\n",
    "for p, proxy in enumerate(proxies):\n",
    "    fprs, tprs, auc_score = auc_overall(df[outcome].astype('float'), df[proxy].astype('float'))\n",
    "    fprs = [100*fpr for fpr in fprs]\n",
    "    tprs = [100*tpr for tpr in tprs]\n",
    "    if dashes[p]:\n",
    "        ax.plot(fprs, tprs, label=proxynames[p] + (' (AUC=%.2f)' % auc_score), dashes=[3, 3], color=colors[p], \n",
    "                linewidth=3)\n",
    "    else:\n",
    "        ax.plot(fprs, tprs, label=proxynames[p]  + (' (AUC=%.2f)' % auc_score), color=colors[p], linewidth=3)\n",
    "    \n",
    "ax.plot([0, 100], [0, 100], label='Random', dashes=[1, 2], color='grey')\n",
    "ax.set_title('ROC Curves')\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate (Recall)')\n",
    "simpleaxis(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2, style='white')\n",
    "fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "\n",
    "for p, proxy in enumerate(proxies):\n",
    "    grid = np.linspace(1, 100, 99)[:-1]\n",
    "    metrics_grid = [metrics(df[outcome].astype('float'), df[proxy].astype('float'), p, p) \n",
    "                    for p in grid]\n",
    "    precisions, recalls = [g[1]*100 for g in metrics_grid], [g[2]*100 for g in \n",
    "                                                             metrics_grid]\n",
    "    if dashes[p]:\n",
    "        ax.plot(grid, recalls, color=colors[p], dashes=[3, 3], label=proxynames[p],\n",
    "               linewidth=3)\n",
    "    else:\n",
    "        ax.plot(grid, recalls, color=colors[p], label=proxynames[p], linewidth=3)\n",
    "\n",
    "ax.plot([0, 100], [0, 100], label='Random', dashes=[1, 2], color='grey')\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlabel('Percentage of Population Targeted')\n",
    "ax.set_ylabel('Precision and Recall')\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "simpleaxis(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = ['prefecture_poverty', 'canton_poverty', 'phone_poverty', 'assetindex', 'pmt']\n",
    "proxynames = ['Prefecture', 'Canton', 'Phone+ML', 'Asset Index', 'PMT']\n",
    "colors = ['indianred', 'darkorange', 'forestgreen', 'dodgerblue', 'darkblue']\n",
    "dashes = [False, False, False, True, True]\n",
    "\n",
    "outcome = 'consumption'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=proxies + [outcome]).copy()\n",
    "\n",
    "# Generate repeated dataframe to account for weighting\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2, style='white')\n",
    "fig, ax = plt.subplots(1, figsize=(20, 10))\n",
    "\n",
    "budget = 100000\n",
    "cashout_fee = 20\n",
    "\n",
    "curves = get_crra(df, proxies, proxynames, 'consumption', budget, cashout_fee)\n",
    "\n",
    "a = 0\n",
    "for outcome, results in curves.items():\n",
    "    percent_targeted, transfersizes, utilities = curves[outcome]\n",
    "    if dashes[a]:\n",
    "        ax.plot(percent_targeted, utilities, label=outcome, color=colors[a], linewidth=3, dashes=[3, 3])\n",
    "    else:\n",
    "        ax.plot(percent_targeted, utilities, label=outcome, color=colors[a], linewidth=3)\n",
    "    results = pd.DataFrame([percent_targeted, transfersizes, utilities]).T\n",
    "    results.columns = ['percent_targeted', 'transfer_size', 'utility']\n",
    "    results = results.sort_values('utility', ascending=False)\n",
    "    best_transfer_size = list(results['transfer_size'])[0]\n",
    "    best_percent_targeted = list(results['percent_targeted'])[0]\n",
    "    ax.axvline(best_percent_targeted, dashes=[1, 1], color = colors[a])\n",
    "    a += 1\n",
    "\n",
    "ax.set_ylim(results['utility'].min(), results['utility'].max())\n",
    "ax.axhline(list(results.sort_values('percent_targeted', ascending=True)['utility'])[-1], color='grey', \n",
    "           dashes=[1, 2], label='UBI')\n",
    "ax.set_xlabel('Fraction of Population Targeted')\n",
    "ax.set_ylabel('Utility')\n",
    "ax.legend(loc='best')\n",
    "simpleaxis(ax)\n",
    "plt.suptitle('Utility Curves', fontsize='large')\n",
    "plt.tight_layout(rect=[0, 0, 1, .95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = ['random', 'prefecture_poverty', 'canton_poverty', 'phone_poverty', 'pmt']\n",
    "proxynames = ['Random', 'Prefecture', 'Canton', 'CDR', 'PMT']\n",
    "colors = ['indianred', 'darkorange', 'mediumseagreen', 'dodgerblue', 'slateblue']\n",
    "\n",
    "outcome = 'consumption'\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=proxies + [outcome]).copy()\n",
    "\n",
    "# Generate repeated dataframe to account for weighting\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_targeted = 29\n",
    "num_targeted = int((percent_targeted/100)*len(df))\n",
    "\n",
    "sns.reset_orig()\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 8))\n",
    "\n",
    "for p, proxy in enumerate(proxies):\n",
    "    \n",
    "    df = df.sort_values(proxy, ascending=True)\n",
    "    targeting_vector = np.concatenate([np.ones(num_targeted), np.zeros(len(df) - num_targeted)])\n",
    "    df['targeted'] = targeting_vector\n",
    "    beneficiaries = df[df['targeted'] == 1]\n",
    "    \n",
    "    beneficiaries = beneficiaries.groupby(['canton', 'prefecture'], as_index=False).agg('count')\\\n",
    "        [['canton', 'prefecture', 'uid']]\\\n",
    "        .rename({'uid':'count'}, axis=1)\n",
    "    total = df.groupby(['canton', 'prefecture'], as_index=False).agg('count')\\\n",
    "        [['canton', 'prefecture', 'uid']]\\\n",
    "        .rename({'uid':'total_count'}, axis=1)\n",
    "    \n",
    "    beneficiaries = beneficiaries.merge(total, on=['canton', 'prefecture'], how='right')\n",
    "    beneficiaries['count'] = beneficiaries['count'].fillna(0)\n",
    "    beneficiaries['percent_targeted'] = beneficiaries['count']/beneficiaries['total_count']\n",
    "    shapefile = gpd.read_file('/home/em/covid/spatial/cantons.geojson')\\\n",
    "        .rename({'Id':'canton'}, axis=1)\n",
    "    \n",
    "    shapefile = shapefile.merge(beneficiaries, on='canton', how='inner')\n",
    "    shapefile['percent_bucket'] = shapefile['percent_targeted']\\\n",
    "        .apply(lambda x: '0-20%' if x < .2 else '20-40%' if x < .4 else '40-60%' if x < .6 else '60-80%' if \n",
    "              x < .8 else '80-100%')\n",
    "    \n",
    "    legend = True if proxy == 'pmt' else False\n",
    "    gpd.read_file('/home/em/covid/spatial/cantons.geojson').plot(color='lightgrey', ax=ax[p])\n",
    "    shapefile.plot(ax=ax[p], column='percent_bucket', linewidth=1, edgecolor='white', cmap='inferno', \n",
    "                   legend=legend, legend_kwds={'title':'Percent Targeted', 'fontsize':'x-large'})\n",
    "\n",
    "    ax[p].axis('off')\n",
    "    ax[p].set_title(proxynames[p], fontsize='x-large')\n",
    "    \n",
    "plt.suptitle('Location of Beneficiaries Under Counterfactual Targeting Approaches', fontsize='xx-large')\n",
    "plt.tight_layout(rect=[0, 0, 1, .91])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
