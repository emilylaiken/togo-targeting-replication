{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Fairness checks\n",
    "Replication code for:\n",
    "- Figure 3\n",
    "- Figure S4\n",
    "- Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from scipy.stats import percentileofscore\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "EXCHANGE_RATE = 572.269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load survey data\n",
    "survey = pd.read_csv('data/survey.csv')\n",
    "\n",
    "# Merge survey data with poverty maps\n",
    "prefectures = gpd.read_file('data/shapefiles/prefectures.geojson')\\\n",
    "    .rename({'poverty':'prefecture_poverty'}, axis=1)\\\n",
    "    [['prefecture', 'prefecture_poverty']]\n",
    "survey = survey.merge(prefectures, on='prefecture', how='left')\n",
    "cantons = gpd.read_file('data/shapefiles/cantons.geojson')\\\n",
    "    .rename({'poverty':'canton_poverty'}, axis=1)\\\n",
    "    [['canton', 'canton_poverty']]\n",
    "survey = survey.merge(cantons, on='canton', how='left')\n",
    "\n",
    "# Merge survey data with phone-based poverty predictions\n",
    "cdr = pd.read_csv('outputs/ml/consumption/LGBM/oos_predictions.csv')\\\n",
    "    [['phone_number', 'predicted']]\\\n",
    "    .rename({'predicted':'phone_poverty'}, axis=1)\n",
    "survey = survey.merge(cdr, on='phone_number', how='left')\n",
    "\n",
    "# Merge survey data with phone-based single feature\n",
    "single_feature = pd.read_csv('data/single_feature.csv')\n",
    "survey = survey.merge(single_feature, on='phone_number', how='left')\n",
    "\n",
    "# Add random outcome\n",
    "np.random.seed(0)\n",
    "survey['random'] = np.random.rand(len(survey))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S4, Figure 3 Panels a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_methods = ['canton_poverty', 'phone_poverty', 'assetindex', 'pmt']\n",
    "outcome = 'consumption'\n",
    "sensitive_vars = ['gender', 'ethnicity', 'religion', 'age_group', 'disability', 'children', 'marital_status', \n",
    "                  'any_vulnerability']\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=targeting_methods + sensitive_vars + [outcome]).copy()\n",
    "\n",
    "# Generate repeated dataframe to account for weighting\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_targeted = 29\n",
    "num_targeted = int(len(df)*(percent_targeted/100))\n",
    "targeting_vector = np.concatenate([np.ones(num_targeted), np.zeros(len(df) - num_targeted)])\n",
    "\n",
    "figsizes = [4, 10, 8, 10, 4, 8, 10]\n",
    "sns.set(font_scale=2, style='white')\n",
    "\n",
    "for d, demo in enumerate(sensitive_vars):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(15, 6), sharey=True)\n",
    "    \n",
    "    for a, proxy in enumerate(targeting_methods):\n",
    "        df = df.sort_values([outcome, 'random'], ascending=True)\n",
    "        df['true_rank'] = range(len(df))\n",
    "        df['targeted_true'] = targeting_vector\n",
    "        df = df.sort_values([proxy, 'random'], ascending=True)\n",
    "        df['proxy_rank'] = range(len(df))\n",
    "        df['targeted_proxy'] = targeting_vector\n",
    "        df['resid'] = (df['proxy_rank'] - df['true_rank'])/(df['true_rank'].max())\n",
    "        \n",
    "        sns.boxplot(data=df.sort_values(demo, ascending=True), x='resid', y=demo, orient='h', ax=ax[a], \n",
    "                    showfliers=False)\n",
    "        ax[a].set_ylabel('')\n",
    "        ax[a].set_xlabel('Error')\n",
    "        ax[a].set_xlim(-1, 1)\n",
    "        ax[a].set_title(targeting_methods[a], fontsize='large')\n",
    "        ax[a].axvline(0, color='grey', dashes=[3, 1])\n",
    "        simpleaxis(ax[a])\n",
    "    \n",
    "    plt.suptitle('Targeting errors, by ' + sensitive_vars[d], fontsize='x-large')\n",
    "    plt.tight_layout(rect=[0, 0, 1, .93])\n",
    "    plt.savefig('/data/togo_anon/paper/figures/fairness_boxplots/' + demo + '_cdr.png', dpi=300)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S5, Figure 3 Panels c and d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeting_methods = ['prefecture_poverty', 'canton_poverty', 'phone_poverty', 'assetindex', 'pmt']\n",
    "outcome = 'consumption'\n",
    "sensitive_vars = ['gender', 'ethnicity', 'religion', 'age_group', 'disability', 'children', 'marital_status', \n",
    "                  'any_vulnerability']\n",
    "\n",
    "# Drop observations missing the value any targeting method\n",
    "df = survey.dropna(subset=targeting_methods + sensitive_vars + [outcome]).copy()\n",
    "\n",
    "# Generate repeated dataframe to account for weighting\n",
    "df['weight'] = df['weight']/df['weight'].min()\n",
    "df = pd.DataFrame(np.repeat(df.values, df['weight'], axis=0), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_targeted = 29\n",
    "num_targeted = int(len(df)*(percent_targeted/100))\n",
    "targeting_vector = np.concatenate([np.ones(num_targeted), np.zeros(len(df) - num_targeted)])\n",
    "\n",
    "figsizes = [4, 10, 8, 10, 4, 8, 10, 4]\n",
    "sns.set(font_scale=2, style='white')\n",
    "\n",
    "for d, demo in enumerate(sensitive_vars):\n",
    "    full_table = []\n",
    "    for a, proxy in enumerate(targeting_methods):\n",
    "        df = df.sort_values([outcome, 'random'], ascending=True)\n",
    "        df['targeted_true'] = targeting_vector\n",
    "        df = df.sort_values([proxy, 'random'], ascending=True)\n",
    "        df['targeted_proxy'] = targeting_vector\n",
    "        \n",
    "        table1 = df.groupby(demo).agg('mean')[['targeted_true', 'targeted_proxy']]\\\n",
    "            .rename({'targeted_true':'percent_deserving', 'targeted_proxy':'percent_receiving'},axis=1)\n",
    "        table1['difference'] = table1['percent_receiving'] - table1['percent_deserving']\n",
    "        table2 = (df.groupby(demo).agg('count')/len(df))[['uid']].rename({'uid':'percent_population'}, axis=1)\n",
    "        table3 = df.groupby(demo).agg('mean')[['targeted_true']].rename({'targeted_true':'percent_poor'}, axis=1)\n",
    "        \n",
    "        table = table2.merge(table3, left_index=True, right_index=True)\\\n",
    "            .merge(table1, left_index=True, right_index=True)\n",
    "        table['group'] = table.index\n",
    "        table = table[['group', 'percent_population', 'percent_poor', 'difference']]\\\n",
    "            .rename({'difference':targeting_methods[a]}, axis=1)\n",
    "        full_table.append(table)\n",
    "\n",
    "    full_table = full_table[0]\\\n",
    "        .merge(full_table[1], on=['group', 'percent_population', 'percent_poor'])\\\n",
    "        .merge(full_table[2], on=['group', 'percent_population', 'percent_poor'])\\\n",
    "        .merge(full_table[3], on=['group', 'percent_population', 'percent_poor'])\\\n",
    "        .merge(full_table[4], on=['group', 'percent_population', 'percent_poor'])\n",
    "    \n",
    "    table = full_table\n",
    "    table['percent_population'] = (100*table['percent_population']).astype('int')\n",
    "    table['percent_poor'] = (100*table['percent_poor']).astype('int')\n",
    "    for proxy in targeting_methods:\n",
    "        table[proxy] = table[proxy]*100\n",
    "        \n",
    "    sns.set(style='white', font_scale=2)\n",
    "    data = table[targeting_methods]\n",
    "\n",
    "    keys = list(data.keys())\n",
    "\n",
    "    N = len(table)\n",
    "    M = len(keys)\n",
    "\n",
    "    ylabels = []\n",
    "    for i in range(len(table)):\n",
    "        ylabels.append('{}\\n{}% of Population\\n{}% Among Poorest'\\\n",
    "                       .format(table.iloc[i]['group'], table.iloc[i]['percent_population'], \n",
    "                               table.iloc[i]['percent_poor']))\n",
    "\n",
    "    ylabels = ylabels[::-1]\n",
    "\n",
    "\n",
    "    xlabels = keys\n",
    "    x, y = np.meshgrid(np.arange(M), np.arange(N))\n",
    "\n",
    "    radius = 15\n",
    "    s = [ [] for i in range(len(keys))]\n",
    "\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(len(data[keys[i]])):\n",
    "            s[i].append(data[keys[i]][j])\n",
    "\n",
    "    arr = np.array(s).transpose()\n",
    "    new_list = []\n",
    "    for i in range(arr.shape[0]-1,-1,-1):\n",
    "        new_list.append(list(arr[i]))\n",
    "\n",
    "    s = new_list\n",
    "    fig = plt.figure(figsize=(10.8,figsizes[d])) \n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    ax.set_title('Demographic Parity: ' + sensitive_vars[d],pad=85, fontsize='large')\n",
    "\n",
    "    s=np.array([np.array(row) for row in s])\n",
    "    R = s\n",
    "    c = R\n",
    "\n",
    "    R = np.log(np.abs(R))/10\n",
    "\n",
    "\n",
    "    circles = [plt.Circle((j,i), radius=r) for r, j, i in zip(R.flatten(), x.flatten(), y.flatten())]\n",
    "    col = PatchCollection(circles, array=c.flatten(), cmap=\"RdBu_r\", edgecolor='grey', linewidth=2)\n",
    "    col.set_clim(vmin=-20, vmax=20)\n",
    "    # math.log(abs(r)) / 10\n",
    "\n",
    "    ax.add_collection(col)\n",
    "    ax.set(xticks=np.arange(M), yticks=np.arange(N),\n",
    "           xticklabels=xlabels, yticklabels=ylabels)\n",
    "    ax.set_xticks(np.arange(M+1)-0.5, minor=True)\n",
    "    ax.set_yticks(np.arange(N+1)-0.5, minor=True)\n",
    "    # ax.grid(which='minor')\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    cbar = fig.colorbar(col, fraction=0.03, pad=0.05,)\n",
    "\n",
    "    cbar.outline.set_edgecolor('white')\n",
    "\n",
    "    cbar.ax.set_ylabel('Percentage Point Difference', labelpad=20)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
